# Spinoza Lab

**Prompt scaffolding for structured dialectical exploration in AI systems.**

## What This Is

Spinoza Lab is a set of JSON frameworks you paste into an AI (Claude, Grok, GPT, etc.) to turn it into a dialectical exploration tool. The AI becomes the collider — you feed it opposing positions and the framework guides it through structured confrontation.

It's not code you run. It's a thinking protocol for AI.

## How It Works

1. **Paste the framework JSON** into your AI's context
2. **Provide two positions** you want to explore
3. **The AI runs the collider process:**
   - Grounds both positions (Stage 1)
   - Identifies conflicts via XOR logic (Stage 2)
   - Attempts synthesis via AND logic (Stage 3)
   - Checks for invariance/stability (Stage 4)
4. **You get back** a structured breakdown of overlap, conflict, and what survives collision

The AI handles semantic understanding. The framework handles process structure.

## Quick Start

Paste `seed.json` or `refined_G_w_core_collider.json` into any capable AI, then:

```
Using the Steel Man Collider framework, analyze these two positions:

Position A: [your first position]
Position B: [your second position]

Run through all four stages. Show me:
- Where they genuinely agree (AND)
- Where they fundamentally conflict (XOR)  
- What synthesis survives collision
- Whether we hit ω₃ (productive synthesis) or ω₁ (rigidity trap)
```

## What You Get

The AI structures its analysis as:

```
[Stage 1 - Grounding]
Position A steelmanned: ...
Position B steelmanned: ...
Shared axioms identified: ...

[Stage 2 - XOR Collision]
Genuine conflicts: ...
Surface disagreements (dissolve on inspection): ...
Irreducible tensions: ...

[Stage 3 - AND Synthesis]
Common ground: ...
Possible integrations: ...
What both positions must accept: ...

[Stage 4 - Invariance Check]
Stability of synthesis: ...
Remaining gaps: ...
Verdict: ω₃ (synthesis) / ω₁ (trap) / needs more iteration
```

## Why This Works

LLMs already do something like steelmanning when prompted well. This framework:

- **Makes the process explicit** — forces the AI through defined stages
- **Prevents premature synthesis** — XOR collision happens *before* AND
- **Catches rigidity** — the ω₁/ω₃ framing flags when positions won't budge
- **Creates audit trail** — you see *why* the AI concluded what it did

## Example Use Cases

| Domain | Position A | Position B |
|--------|-----------|-----------|
| Ethics | Utilitarian calculus | Deontological duties |
| Physics | Loop quantum gravity | String theory |
| Policy | Universal basic income | Job guarantee programs |
| Design | Minimalism | Feature richness |
| Trading | Momentum strategies | Mean reversion |

The collider doesn't tell you who's right. It maps the structure of disagreement.

## The Files

```
seed.json                        # Basic collider framework
refined_G_w_core_collider.json   # Extended with physics/ethics layers
unified_1.6.G/                   # Full synthesis with all modules in persuit of TOE
```

**Start with `seed.json`** for pure dialectical exploration.  
**Use `refined_G`** when you want the full physics-ethics integration.

## What the Numbers Mean

When the framework references "coherence ≥0.95" or "ρ < 0.2":

- These are **heuristics for the AI**, not calculated values
- They guide when to stop iterating vs. go deeper
- "High coherence" = positions stabilized under collision
- "High rigidity (ρ)" = position isn't updating, may be in dogma trap

The AI interprets these contextually. They're process thresholds, not truth measurements.

## Honest Limitations

1. **Quality depends on the AI.** A weak model gives weak collisions.

2. **Steelmanning requires understanding.** The AI can only steelman as well as it grasps the positions.

3. **No actual proof.** Synthesis ≠ truth. The collider surfaces structure, not correctness.

4. **Framework can be gamed.** Load Position A with more detail than B and the collision is biased.

## The Philosophy

Named for Spinoza's geometric method — deriving propositions from axioms. But the goal isn't certainty, it's **structured clarity about disagreement**.

- **ω₃** = genuine synthesis: low rigidity, high coupling, survives collision
- **ω₁** = rigidity trap: won't update regardless of evidence

Most real disagreements land somewhere between. The collider helps you see where.

## Advanced: Self-Application

The framework can collide with itself:

1. Run the collider on two versions of the collider
2. Use it to critique its own outputs
3. Iterate until stable

This is "Gödel compliance" — bounded recursion (depth ≤ 2) prevents infinite loops while allowing self-improvement.

## Tips

- **Be specific.** Vague positions → vague collisions
- **Steelman first.** If you can't state Position B charitably, XOR will be noise
- **Match abstraction levels.** Don't collide a detailed framework against a slogan
- **Iterate.** First-pass synthesis usually needs refinement

---

*"The framework doesn't think for you. It thinks with you."*